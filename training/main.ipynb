{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd3784e7",
   "metadata": {},
   "source": [
    "Training a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1506559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of clones: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [00:03<02:36,  1.60s/it, train_bps=0.0165]\n",
      "  2%|▏         | 2/100 [00:01<01:11,  1.38it/s, train_bps=0.0158]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0:\n",
      "observation_lls=tensor([[-1.0867, -1.1410, -1.0696],\n",
      "        [-1.0867, -1.1410, -1.0696],\n",
      "        [-1.0768, -1.1269, -1.0928],\n",
      "        [-1.0867, -1.1410, -1.0696],\n",
      "        [-1.0768, -1.1269, -1.0928],\n",
      "        [-1.0768, -1.1269, -1.0928],\n",
      "        [-1.0867, -1.1410, -1.0696],\n",
      "        [-1.0867, -1.1410, -1.0696],\n",
      "        [-1.1475, -1.1155, -1.0362],\n",
      "        [-1.0867, -1.1410, -1.0696],\n",
      "        [-1.0768, -1.1269, -1.0928],\n",
      "        [-1.0768, -1.1269, -1.0928],\n",
      "        [-1.0867, -1.1410, -1.0696],\n",
      "        [-1.0768, -1.1269, -1.0928],\n",
      "        [-1.0768, -1.1269, -1.0928],\n",
      "        [-1.0867, -1.1410, -1.0696],\n",
      "        [-1.1475, -1.1155, -1.0362],\n",
      "        [-1.1475, -1.1155, -1.0362],\n",
      "        [-1.1475, -1.1155, -1.0362],\n",
      "        [-1.1475, -1.1155, -1.0362],\n",
      "        [-1.1475, -1.1155, -1.0362],\n",
      "        [-1.1475, -1.1155, -1.0362],\n",
      "        [-1.1475, -1.1155, -1.0362],\n",
      "        [-1.0867, -1.1410, -1.0696],\n",
      "        [-1.0867, -1.1410, -1.0696],\n",
      "        [-1.1475, -1.1155, -1.0362],\n",
      "        [-1.1475, -1.1155, -1.0362],\n",
      "        [-1.1475, -1.1155, -1.0362],\n",
      "        [-1.1475, -1.1155, -1.0362],\n",
      "        [-1.1475, -1.1155, -1.0362],\n",
      "        [-1.1475, -1.1155, -1.0362],\n",
      "        [-1.1475, -1.1155, -1.0362],\n",
      "        [-1.0867, -1.1410, -1.0696],\n",
      "        [-1.0867, -1.1410, -1.0696],\n",
      "        [-1.0768, -1.1269, -1.0928],\n",
      "        [-1.0768, -1.1269, -1.0928],\n",
      "        [-1.0867, -1.1410, -1.0696],\n",
      "        [-1.1475, -1.1155, -1.0362],\n",
      "        [-1.1475, -1.1155, -1.0362],\n",
      "        [-1.1475, -1.1155, -1.0362],\n",
      "        [-1.1475, -1.1155, -1.0362],\n",
      "        [-1.1475, -1.1155, -1.0362],\n",
      "        [-1.0867, -1.1410, -1.0696],\n",
      "        [-1.0867, -1.1410, -1.0696],\n",
      "        [-1.1475, -1.1155, -1.0362],\n",
      "        [-1.0867, -1.1410, -1.0696],\n",
      "        [-1.0768, -1.1269, -1.0928],\n",
      "        [-1.0768, -1.1269, -1.0928],\n",
      "        [-1.0768, -1.1269, -1.0928],\n",
      "        [-1.0768, -1.1269, -1.0928],\n",
      "        [-1.0867, -1.1410, -1.0696],\n",
      "        [-1.0768, -1.1269, -1.0928],\n",
      "        [-1.0768, -1.1269, -1.0928],\n",
      "        [-1.0768, -1.1269, -1.0928],\n",
      "        [-1.0867, -1.1410, -1.0696],\n",
      "        [-1.0867, -1.1410, -1.0696],\n",
      "        [-1.0867, -1.1410, -1.0696],\n",
      "        [-1.0867, -1.1410, -1.0696],\n",
      "        [-1.0867, -1.1410, -1.0696],\n",
      "        [-1.0867, -1.1410, -1.0696],\n",
      "        [-1.0768, -1.1269, -1.0928],\n",
      "        [-1.0867, -1.1410, -1.0696],\n",
      "        [-1.0867, -1.1410, -1.0696],\n",
      "        [-1.1475, -1.1155, -1.0362],\n",
      "        [-1.0867, -1.1410, -1.0696],\n",
      "        [-1.1475, -1.1155, -1.0362],\n",
      "        [-1.1475, -1.1155, -1.0362],\n",
      "        [-1.1475, -1.1155, -1.0362],\n",
      "        [-1.1475, -1.1155, -1.0362],\n",
      "        [-1.1475, -1.1155, -1.0362],\n",
      "        [-1.0867, -1.1410, -1.0696],\n",
      "        [-1.0768, -1.1269, -1.0928],\n",
      "        [-1.0768, -1.1269, -1.0928],\n",
      "        [-1.0768, -1.1269, -1.0928],\n",
      "        [-1.0768, -1.1269, -1.0928],\n",
      "        [-1.0768, -1.1269, -1.0928],\n",
      "        [-1.0768, -1.1269, -1.0928],\n",
      "        [-1.0768, -1.1269, -1.0928],\n",
      "        [-1.0768, -1.1269, -1.0928],\n",
      "        [-1.0768, -1.1269, -1.0928],\n",
      "        [-1.0768, -1.1269, -1.0928],\n",
      "        [-1.0768, -1.1269, -1.0928],\n",
      "        [-1.0768, -1.1269, -1.0928],\n",
      "        [-1.0768, -1.1269, -1.0928],\n",
      "        [-1.0867, -1.1410, -1.0696],\n",
      "        [-1.0867, -1.1410, -1.0696],\n",
      "        [-1.0768, -1.1269, -1.0928],\n",
      "        [-1.0768, -1.1269, -1.0928],\n",
      "        [-1.0768, -1.1269, -1.0928],\n",
      "        [-1.0768, -1.1269, -1.0928],\n",
      "        [-1.0768, -1.1269, -1.0928],\n",
      "        [-1.0768, -1.1269, -1.0928],\n",
      "        [-1.0768, -1.1269, -1.0928],\n",
      "        [-1.0867, -1.1410, -1.0696],\n",
      "        [-1.0867, -1.1410, -1.0696],\n",
      "        [-1.0867, -1.1410, -1.0696],\n",
      "        [-1.0867, -1.1410, -1.0696],\n",
      "        [-1.0768, -1.1269, -1.0928],\n",
      "        [-1.0768, -1.1269, -1.0928],\n",
      "        [-1.0768, -1.1269, -1.0928]], grad_fn=<LogSoftmaxBackward0>)\n",
      "> \u001b[0;32m/Users/simon/code/pushworld_bot/training/encoder_training.py\u001b[0m(103)\u001b[0;36mlog_forward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    101 \u001b[0;31m    \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    102 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 103 \u001b[0;31m    \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    104 \u001b[0;31m        \u001b[0mlog_T_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_T\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    105 \u001b[0;31m        \u001b[0mlog_alpha\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogsumexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_alpha\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlog_T_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mobservation_lls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#TODO: understand indexing here, if you aren't gonna use the E matrix directly then it makes sense to just pass n_clones into this function instead of E\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "--KeyboardInterrupt--\n",
      "\n",
      "KeyboardInterrupt: Interrupted by user\n",
      "log_likelihood=-108.86244244258158\n",
      "Iteration 1:\n",
      "observation_lls=tensor([[nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>)\n",
      "> \u001b[0;32m/Users/simon/code/pushworld_bot/training/encoder_training.py\u001b[0m(103)\u001b[0;36mlog_forward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    101 \u001b[0;31m    \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    102 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 103 \u001b[0;31m    \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    104 \u001b[0;31m        \u001b[0mlog_T_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_T\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    105 \u001b[0;31m        \u001b[0mlog_alpha\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogsumexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_alpha\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlog_T_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mobservation_lls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#TODO: understand indexing here, if you aren't gonna use the E matrix directly then it makes sense to just pass n_clones into this function instead of E\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from experiment import Experiment\n",
    "\n",
    "# Before running, set your parameters in the config file in this directory. You can see all possible parameters in the schem.yaml file in this directory\n",
    "config_path = \"config.yaml\"\n",
    "\n",
    "exp = Experiment(config_path, name=\"exp2\", overwrite=True)\n",
    "exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4134691c",
   "metadata": {},
   "source": [
    "Analysis of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c81dee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"600\" viewBox=\"0 0 600 600\">\n",
       "<defs>\n",
       "<g>\n",
       "<g id=\"glyph-0-0\">\n",
       "<path d=\"M 3.789062 -9.789062 C 5.054688 -9.789062 5.96875 -9.265625 6.535156 -8.222656 C 6.972656 -7.417969 7.191406 -6.3125 7.191406 -4.90625 C 7.191406 -3.578125 6.992188 -2.476562 6.597656 -1.605469 C 6.023438 -0.359375 5.082031 0.265625 3.78125 0.265625 C 2.605469 0.265625 1.730469 -0.242188 1.15625 -1.265625 C 0.675781 -2.117188 0.4375 -3.261719 0.4375 -4.695312 C 0.4375 -5.808594 0.582031 -6.761719 0.867188 -7.5625 C 1.40625 -9.046875 2.378906 -9.789062 3.789062 -9.789062 Z M 3.773438 -0.855469 C 4.410156 -0.855469 4.917969 -1.136719 5.296875 -1.703125 C 5.675781 -2.265625 5.867188 -3.320312 5.867188 -4.859375 C 5.867188 -5.972656 5.726562 -6.886719 5.453125 -7.605469 C 5.179688 -8.324219 4.652344 -8.679688 3.863281 -8.679688 C 3.136719 -8.679688 2.609375 -8.339844 2.273438 -7.660156 C 1.9375 -6.976562 1.769531 -5.976562 1.769531 -4.648438 C 1.769531 -3.648438 1.878906 -2.847656 2.09375 -2.242188 C 2.421875 -1.316406 2.980469 -0.855469 3.773438 -0.855469 Z M 3.773438 -0.855469 \"/>\n",
       "</g>\n",
       "<g id=\"glyph-0-1\">\n",
       "<path d=\"M 1.339844 -6.929688 L 1.339844 -7.875 C 2.226562 -7.960938 2.847656 -8.105469 3.199219 -8.308594 C 3.550781 -8.511719 3.8125 -8.992188 3.984375 -9.75 L 4.957031 -9.75 L 4.957031 0 L 3.644531 0 L 3.644531 -6.929688 Z M 1.339844 -6.929688 \"/>\n",
       "</g>\n",
       "<g id=\"glyph-0-2\">\n",
       "<path d=\"M 0.4375 0 C 0.484375 -0.84375 0.65625 -1.578125 0.960938 -2.203125 C 1.265625 -2.828125 1.855469 -3.394531 2.734375 -3.902344 L 4.046875 -4.664062 C 4.632812 -5.003906 5.046875 -5.296875 5.285156 -5.539062 C 5.65625 -5.914062 5.84375 -6.347656 5.84375 -6.835938 C 5.84375 -7.40625 5.671875 -7.859375 5.332031 -8.191406 C 4.992188 -8.527344 4.535156 -8.695312 3.964844 -8.695312 C 3.121094 -8.695312 2.539062 -8.375 2.214844 -7.738281 C 2.042969 -7.398438 1.945312 -6.921875 1.929688 -6.316406 L 0.675781 -6.316406 C 0.691406 -7.167969 0.847656 -7.863281 1.148438 -8.402344 C 1.679688 -9.351562 2.621094 -9.824219 3.972656 -9.824219 C 5.09375 -9.824219 5.910156 -9.519531 6.429688 -8.914062 C 6.945312 -8.308594 7.203125 -7.632812 7.203125 -6.890625 C 7.203125 -6.105469 6.929688 -5.4375 6.378906 -4.882812 C 6.058594 -4.558594 5.488281 -4.164062 4.664062 -3.703125 L 3.726562 -3.1875 C 3.28125 -2.941406 2.929688 -2.703125 2.671875 -2.480469 C 2.21875 -2.085938 1.929688 -1.644531 1.8125 -1.164062 L 7.15625 -1.164062 L 7.15625 0 Z M 0.4375 0 \"/>\n",
       "</g>\n",
       "</g>\n",
       "</defs>\n",
       "<rect x=\"-60\" y=\"-60\" width=\"720\" height=\"720\" fill=\"rgb(100%, 100%, 100%)\" fill-opacity=\"1\"/>\n",
       "<path fill=\"none\" stroke-width=\"1\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" stroke=\"rgb(26.666667%, 26.666667%, 26.666667%)\" stroke-opacity=\"1\" stroke-miterlimit=\"10\" d=\"M 338.453125 284.054688 C 338.453125 296.480469 328.378906 306.554688 315.953125 306.554688 C 303.527344 306.554688 293.453125 296.480469 293.453125 284.054688 C 293.453125 271.628906 303.527344 261.554688 315.953125 261.554688 C 328.378906 261.554688 338.453125 271.628906 338.453125 284.054688 \"/>\n",
       "<path fill=\"none\" stroke-width=\"1\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" stroke=\"rgb(26.666667%, 26.666667%, 26.666667%)\" stroke-opacity=\"1\" stroke-miterlimit=\"10\" d=\"M 300.042969 299.964844 C 312.363281 437.019531 385.265625 523.617188 521.054688 545.363281 \"/>\n",
       "<path fill-rule=\"nonzero\" fill=\"rgb(26.666667%, 26.666667%, 26.666667%)\" fill-opacity=\"1\" d=\"M 535.140625 547.621094 L 520.324219 549.941406 L 521.789062 540.789062 L 535.140625 547.621094 \"/>\n",
       "<path fill=\"none\" stroke-width=\"1\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" stroke=\"rgb(26.666667%, 26.666667%, 26.666667%)\" stroke-opacity=\"1\" stroke-miterlimit=\"10\" d=\"M 300.042969 299.964844 C 287.679688 162.910156 214.746094 76.332031 78.945312 54.625 \"/>\n",
       "<path fill-rule=\"nonzero\" fill=\"rgb(26.666667%, 26.666667%, 26.666667%)\" fill-opacity=\"1\" d=\"M 64.859375 52.375 L 79.675781 50.050781 L 78.214844 59.203125 L 64.859375 52.375 \"/>\n",
       "<path fill=\"none\" stroke-width=\"1\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" stroke=\"rgb(26.666667%, 26.666667%, 26.666667%)\" stroke-opacity=\"1\" stroke-miterlimit=\"10\" d=\"M 550 550 C 537.679688 412.945312 464.777344 326.347656 328.988281 304.601562 \"/>\n",
       "<path fill-rule=\"nonzero\" fill=\"rgb(26.666667%, 26.666667%, 26.666667%)\" fill-opacity=\"1\" d=\"M 314.902344 302.34375 L 329.71875 300.023438 L 328.253906 309.179688 L 314.902344 302.34375 \"/>\n",
       "<path fill=\"none\" stroke-width=\"1\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" stroke=\"rgb(26.666667%, 26.666667%, 26.666667%)\" stroke-opacity=\"1\" stroke-miterlimit=\"10\" d=\"M 588.410156 534.089844 C 588.410156 546.515625 578.335938 556.589844 565.910156 556.589844 C 553.484375 556.589844 543.410156 546.515625 543.410156 534.089844 C 543.410156 521.664062 553.484375 511.589844 565.910156 511.589844 C 578.335938 511.589844 588.410156 521.664062 588.410156 534.089844 \"/>\n",
       "<path fill=\"none\" stroke-width=\"1\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" stroke=\"rgb(26.666667%, 26.666667%, 26.666667%)\" stroke-opacity=\"1\" stroke-miterlimit=\"10\" d=\"M 50 50 C 62.363281 187.054688 135.296875 273.632812 271.097656 295.339844 \"/>\n",
       "<path fill-rule=\"nonzero\" fill=\"rgb(26.666667%, 26.666667%, 26.666667%)\" fill-opacity=\"1\" d=\"M 285.183594 297.589844 L 270.367188 299.914062 L 271.828125 290.761719 L 285.183594 297.589844 \"/>\n",
       "<path fill=\"none\" stroke-width=\"1\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" stroke=\"rgb(26.666667%, 26.666667%, 26.666667%)\" stroke-opacity=\"1\" stroke-miterlimit=\"10\" d=\"M 88.410156 34.089844 C 88.410156 46.515625 78.335938 56.589844 65.910156 56.589844 C 53.484375 56.589844 43.410156 46.515625 43.410156 34.089844 C 43.410156 21.664062 53.484375 11.589844 65.910156 11.589844 C 78.335938 11.589844 88.410156 21.664062 88.410156 34.089844 \"/>\n",
       "<path fill-rule=\"nonzero\" fill=\"rgb(61.960784%, 0.392157%, 25.882353%)\" fill-opacity=\"1\" stroke-width=\"1\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" stroke=\"rgb(0%, 0%, 0%)\" stroke-opacity=\"1\" stroke-miterlimit=\"10\" d=\"M 315.042969 299.964844 C 315.042969 308.25 308.328125 314.964844 300.042969 314.964844 C 291.757812 314.964844 285.042969 308.25 285.042969 299.964844 C 285.042969 291.679688 291.757812 284.964844 300.042969 284.964844 C 308.328125 284.964844 315.042969 291.679688 315.042969 299.964844 \"/>\n",
       "<path fill-rule=\"nonzero\" fill=\"rgb(99.807766%, 99.923106%, 74.602076%)\" fill-opacity=\"1\" stroke-width=\"1\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" stroke=\"rgb(0%, 0%, 0%)\" stroke-opacity=\"1\" stroke-miterlimit=\"10\" d=\"M 565 550 C 565 558.285156 558.285156 565 550 565 C 541.714844 565 535 558.285156 535 550 C 535 541.714844 541.714844 535 550 535 C 558.285156 535 565 541.714844 565 550 \"/>\n",
       "<path fill-rule=\"nonzero\" fill=\"rgb(36.862745%, 30.980392%, 63.529412%)\" fill-opacity=\"1\" stroke-width=\"1\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" stroke=\"rgb(0%, 0%, 0%)\" stroke-opacity=\"1\" stroke-miterlimit=\"10\" d=\"M 65 50 C 65 58.285156 58.285156 65 50 65 C 41.714844 65 35 58.285156 35 50 C 35 41.714844 41.714844 35 50 35 C 58.285156 35 65 41.714844 65 50 \"/>\n",
       "<g fill=\"rgb(0%, 0%, 0%)\" fill-opacity=\"1\">\n",
       "<use xlink:href=\"#glyph-0-0\" x=\"296.230469\" y=\"306.46875\"/>\n",
       "</g>\n",
       "<g fill=\"rgb(0%, 0%, 0%)\" fill-opacity=\"1\">\n",
       "<use xlink:href=\"#glyph-0-1\" x=\"546.851562\" y=\"556.484375\"/>\n",
       "</g>\n",
       "<g fill=\"rgb(0%, 0%, 0%)\" fill-opacity=\"1\">\n",
       "<use xlink:href=\"#glyph-0-2\" x=\"46.179688\" y=\"56.523438\"/>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<igraph.drawing.cairo.plot.CairoPlot at 0x159d1d8d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "image/svg+xml": {
       "isolated": true
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from experiment import ExperimentData\n",
    "from cscg_helpers import Plotting\n",
    "\n",
    "e = ExperimentData.load(experiment_name=\"exp2\")\n",
    "Plotting.plot_graph(e.chmm, e.x, e.a, output_file=\"../experiments/simple_room/cscg.png\")\n",
    "\n",
    "# Plots the cscg part of the model. Each unique color represents a unique observation. Note that since the experiment\n",
    "# uses an int encoder, every single state gets mapped to a unique observation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18adb92e",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from analysis import Analysis\n",
    "\n",
    "# Use \"a\", \"r\" and arrow keys to move the agent while viewing the inferred state\n",
    "Analysis.simulate_trained_model(experiment_name=\"exp2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69cac3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pushworld_bot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
